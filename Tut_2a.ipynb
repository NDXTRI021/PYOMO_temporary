{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Chapter 2: Trajectory Optimisation\n",
    "---\n",
    "# **Tutorial 2.a: Optimal Pendulum Swing Up with PYOMO**\n",
    "**Aim:** To create an optimization model from the double pendulum we've constructed in symbolic toolbox, and solve it for the optimal swing-up motion.\n",
    "\n",
    "**Further reading:** <a href = http://www.matthewpeterkelly.com/tutorials/trajectoryOptimization/index.html> This blog is a perfect introduction to trajectory optimization that will give you a solid overview of the problem and all the terminology you need. Matthew Kelly is a good dude :)</a> It might be worth checking out the <a href=https://pyomo.readthedocs.io/en/stable/>Pyomo documentation</a>, but it's a bit hit and miss... IMO the textbook 'Pyomo - Optimization Modeling in Python by William E. Hart is much better.\n",
    "### **Contents**:\n",
    "* [Trajectory Optimization 101](#Trajectory-Optimization-101)\n",
    "* [Lambdify](#Lambdify---how-to-get-functions-from-symbolic-expressions)\n",
    "* [Problem Formulation](#Problem-Formulation)\n",
    "* [Modelling in Pyomo](#Modelling-in-Pyomo)\n",
    "* [Initialization](#Initialization)\n",
    "* [Solve](#Solve!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Trajectory Optimization 101**\n",
    "\n",
    "**What is a trajectory?**\n",
    "A trajectory is just a time series: the behaviour of one or more variables sampled over time. In our specific cases, the variables we're tracking are the ones we need to describe the motion of a system over time, and the forces that drive that motion.\n",
    "\n",
    "**What does it mean to 'optimize' a trajectory?**\n",
    "Trajectory optimization problems are often 'boundary value problems': the system has a known starting point, and a known ending point that we want it to get to. E.g. for our pendulum swing-up, we want it to start at rest hanging down at [0,0], and we want it to end at rest pointing straight up at [$\\pi$,0]. \n",
    "\n",
    "Thing is, there are infinitely many trajectories that could get us from point A to point B: maybe the pendulum swings up clockwise... Maybe it swings up anticlockwise... Maybe it flails around in the precise way for its endpoint to write out all the lyrics to MCR's *Welcome to the Black Parade* in perfect air-cursive before getting there. The point of optimization is to find the trajectory that best minimizes some *cost function* (aka. the *objective function*).\n",
    "\n",
    "If your objective is rapid motion, you might want to minimize the time it takes to swing up. If your objective is efficiency, you might want to minimize the torque applied over the course of the motion. Maybe you want to minimize the total horizontal space it needs to perform the manoeuvre, whatever. Part of the art of this field is finding the right cost function. (But more on that just now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# Pyomo stuff\n",
    "from pyomo.environ import*\n",
    "from pyomo.opt import SolverFactory\n",
    "from pyomo.opt import SolverStatus, TerminationCondition\n",
    "\n",
    "# create the model\n",
    "m = ConcreteModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE FROM CHAPTER 1\n",
    "\n",
    "# import libraries\n",
    "import sympy as sym\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, HTML #for pretty printing\n",
    "display(HTML(\"<style>.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea { max-height: 32em; }</style>\"))\n",
    "\n",
    "# create symbolic variables\n",
    "\n",
    "# system parameters\n",
    "g = sym.symbols('g')\n",
    "m1 ,  m2 = sym.symbols([ 'm_{1}', 'm_{2}']) # mass of links\n",
    "l1 ,  l2 = sym.symbols([ 'l_{1}', 'l_{2}']) # length of links\n",
    "d1 ,  d2 = sym.symbols([ 'd_{1}', 'd_{2}']) # distance to COM of links\n",
    "In1, In2 = sym.symbols(['In_{1}','In_{2}']) # moment of intertia of links\n",
    "\n",
    "# generalized coordinates\n",
    "X0, Y0 = sym.symbols(['X_{0}','Y_{0}']) # fixed position of first link\n",
    "\n",
    "th1  ,  th2 = sym.symbols([       '\\\\theta_{1}',       '\\\\theta_{2}']) #positions\n",
    "dth1 , dth2 = sym.symbols([ '\\dot{\\\\theta}_{1}', '\\dot{\\\\theta}_{2}']) #velocities\n",
    "ddth1,ddth2 = sym.symbols(['\\ddot{\\\\theta}_{1}','\\ddot{\\\\theta}_{2}']) #accelerations\n",
    "\n",
    "q   = sym.Matrix([  [th1],  [th2]]) #group into matrices\n",
    "dq  = sym.Matrix([ [dth1], [dth2]])\n",
    "ddq = sym.Matrix([[ddth1],[ddth2]])\n",
    "\n",
    "# STEP 1: system space coordinates written in terms of the generalised coordinates\n",
    "\n",
    "# helper functions\n",
    "def Rotate(v, th):\n",
    "    # the 2D system space coordinates are [x;y;th], so we need a rotation function that can work with this\n",
    "    R = sym.Matrix([[sym.cos(th), -sym.sin(th), 0],\n",
    "                    [sym.sin(th),  sym.cos(th), 0],\n",
    "                    [          0,            0, 1]]) # rotation matrix, augmented because of the theta element of the vector\n",
    "    S = sym.Matrix([[0],[0],[th]]) # angle of rotation\n",
    "    return R*v + S # coordinates after rotation\n",
    "\n",
    "def GetXY(v):\n",
    "    # this function is for applying a position-only offset (preserves the angle)\n",
    "    vector_mask = sym.Matrix([[1],[1],[0]]) # gets rid of angle component of vector when multiplied elementwise\n",
    "    return v.multiply_elementwise(vector_mask)\n",
    "\n",
    "# Absolute orientations\n",
    "\n",
    "# positions of each link in their own reference frames\n",
    "r0   = sym.Matrix([[X0],   [Y0],[0]]) # position of the origin of the first link\n",
    "r1_1 = sym.Matrix([[0],[-d1*l1],[0]]) # read as: position r1, in frame 1\n",
    "r2_2 = sym.Matrix([[0],[-d2*l2],[0]]) # minus sign to show that links point downwards\n",
    "\n",
    "# positions of each link, moved into the inertial frame\n",
    "r1_0 = Rotate(r1_1, th1) + GetXY(r0)\n",
    "\n",
    "r2_1 = Rotate(r2_2, th2-th1) + GetXY(r1_1/d1*(1-d1)) # GetXY of the bottom portion of link 1\n",
    "r2_0 = Rotate(r2_1, th1) + GetXY(r1_0) # this code is improved upon in tut 3\n",
    "\n",
    "# end position:\n",
    "rEnd_0 = Rotate(r2_2/d2*(1-d2), th2) + GetXY(r2_0) # bottom portion of link rotated into inertial, plus r2_0\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "# STEP 2: generate expressions for the system space velocities\n",
    "\n",
    "dr1 = r1_0.jacobian(q)*dq\n",
    "dr2 = r2_0.jacobian(q)*dq\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "# STEP 3: generate expressions for the kinetic and potential energy\n",
    "\n",
    "# helper functions\n",
    "def Ek(m, In, dr):\n",
    "    InM = sym.Matrix([[m,0,0],[0,m,0],[0,0,In]])\n",
    "    return 0.5*dr.T*InM*dr\n",
    "\n",
    "def Ep(m, r):\n",
    "    return sym.Matrix([m*g*r[1]])\n",
    "\n",
    "# expressions\n",
    "T = Ek(m1, In1, dr1) + Ek(m2, In2, dr2)\n",
    "V = Ep(m1, r1_0) + Ep(m2, r2_0)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "# STEP 4: calculate each term of the Lagrange equation\n",
    "\n",
    "# term 1\n",
    "Lg1 = sym.zeros(1,len(q))\n",
    "for i in range(len(q)):\n",
    "    dT_ddq = sym.diff(T,dq[i]) # get partial of T in dq_i\n",
    "    Lg1[i] = dT_ddq.jacobian(q)*dq + dT_ddq.jacobian(dq)*ddq #...then get time derivative of that partial\n",
    "\n",
    "# term 2 = 0\n",
    "# term 3\n",
    "Lg3 = T.jacobian(q) # partial of T in q\n",
    "\n",
    "# term 4\n",
    "Lg4 = V.jacobian(q) # partial of U in q\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "# STEP 5: calculate generalized forces\n",
    "\n",
    "tau = sym.symbols('tau') # arbitrary control torque\n",
    "tau_l1 = sym.Matrix([[0],[0],[-tau]]) # the world frame torque acting on the first link\n",
    "tau_l2 = sym.Matrix([[0],[0],[ tau]]) # the world frame torque acting on the last link\n",
    "\n",
    "Qtau = r2_0.jacobian(q).T*tau_l2 + r1_0.jacobian(q).T*tau_l1\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "\n",
    "# STEP 6: put it all together\n",
    "\n",
    "EOM = Lg1 - Lg3 + Lg4 - Qtau.T\n",
    "EOM = EOM.T\n",
    "\n",
    "display(EOM[1].simplify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lambdify - how to get functions from symbolic expressions**\n",
    "To use the symbolic expressions in a constraint, we first need to convert them to lambda functions so we can easily substitute our variables and parameters in.\n",
    "\n",
    "### How this works in our code:\n",
    "- **Create the `sym_list`:** a list of Sympy variables that are in the EOMs. We need to substitute numerical values for these later.\n",
    "- **Lambdify the EOMs:** Each EOM is lambdified with respect to the `sym_list`, and the `sin` and `cos` functions are replaced with numpy versions.\n",
    "- **Create `get_var_list` function:** this returns the `var_list` (a list of the numerical values to be substituted into the lambdified EOMs). These values are accessed from the corresponding Pyomo variabled at the time of the function call.\n",
    "- **Define the `dynamics` constraint:** (this is later in the code). We define a constraint that calls the `get_var_list` function and substitutes the numerical values into the EOMs, ensuring that the EOMs evaluate to 0.\n",
    "\n",
    "\\***NOTE:** the variables in the `var_list` must match the order of the variables in the `sym_list`, or you could get weird issues. An easy example to catch would be gravity acting sideways (if x and y are mixed up), but most times it'd likely be a lot easier to spot the error in the code than in the animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lambdify the EOM\n",
    "\n",
    "func_map = {'sin':sin, 'cos':cos} \n",
    "# You need to tell 'lambdify' which symbolic toolbox functions = which functions from other modules.\n",
    "# Here, we want the symbolic sin and cos to map to pyomo's sin and cos.\n",
    "# (Yes, pyomo has its own trig functions that are distinct from numpy's or math's. You need to use them.)\n",
    "\n",
    "sym_list = [g,\n",
    "            m1, m2, l1, l2, d1, d2, In1, In2,\n",
    "            X0, Y0, th1, th2, dth1, dth2, ddth1, ddth2,\n",
    "            tau] # list of the symbols that will be substituted with inputs\n",
    "\n",
    "lamb_EOM  = {} # dictionaries are honestly my favourite thing about Python\n",
    "for i in range(1,3): \n",
    "    lamb_EOM[i] = sym.lambdify(sym_list,EOM[i-1],modules = [func_map])\n",
    "# We can contain the EOMs for all coordinates in a dictionary so we just need one constraint definition for the dynamics.\n",
    "\n",
    "# variable list to be used in the dynamics constraints later.\n",
    "# could've been typed out later, but here it's easier to see if anything's in the wrong order\n",
    "def get_var_list(m,n):\n",
    "    # list the model versions of all quantities in the same order as sym_list\n",
    "    var_list = [m.g,\n",
    "                m.m[1], m.m[2], m.len[1], m.len[2], m.dCOM[1], m.dCOM[2], m.In[1], m.In[2],\n",
    "                m.X0, m.Y0, m.th[n,1], m.th[n,2], m.dth[n,1], m.dth[n,2], m.ddth[n,1], m.ddth[n,2],\n",
    "                m.Tc[n]]\n",
    "    # note that some quantities contain \"n\"\n",
    "    return var_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Problem Formulation**\n",
    "\n",
    "There are many different ways to do trajectory optimization, but the one we have chosen is the _transcription_ approach, where we _transcribe_ the trajectory optimization into a nonlinear programming problem (NLP). You might have encountered the basics of _linear programming_ in high school, where you probably used it to solve some kind of simple optimization, such as figuring out how many of each type of sandwich should be stocked at the tuck shop to maximize profits, subject to constraints like\n",
    "- No more than 200 sandwiches can be stored at a time\n",
    "- At least 40 cheese sandwiches must be available\n",
    "If so, you probably remember drawing these constraints on a graph, highlighting the _feasible region_ where all of them are satisfied, and finding the point within that where you are scoring the most bread for your bread.\n",
    "\n",
    "These linear programs were very simple: you never had more than two _decision variables_ (number of thing A, number of thing B), since this is how many you can plot on a 2D graph, and all the constraints were _linear_ i.e. able to be represented using straight lines, but they contain all the same elements of an optimization program. The difference with NLPs is that the constraints can be nonlinear. Another difference with the problems we'll be looking at is the sheer scale: they'll often have tens, or even hundreds of thousands of variables and constraints - far more than can be comfortably dealt with by hand.\n",
    "\n",
    "Luckily, you don't need to know how to solve such a monstrosity, because smart maths people have already figured it out and made some general-purpose NLP solving algorithms - some of which are open source. So, all you need to know how to do is describe your trajectory optimization problem in terms of a NLP, and then you can use one of these solvers to find a result.\n",
    "\n",
    "Algebraic modelling languages (AMLs), such as the Pyomo library in Python, facilitate this activity. In Pyomo, a problem is referred to as a \"model\": it's a big box filled with variables, constraints, parameters and a cost function. You pass the box to a solver and (eventually) get a trajectory out.\n",
    "\n",
    "Pyomo has two types of model: a *concrete* model, where all the parameters are fixed up front, and an *abstract model*, where the values are left symbolic and you have to specify them using a configuration file before you solve. I have yet to find a good enough use case for the abstract one to bother learning how to use them; if I have to solve for say, a variety of different link lengths, I'll just hard code those changes between runs. But maybe that's just me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modelling in Pyomo**\n",
    "Pyomo has a cool object-oriented approach to modelling problems: the model is an object, and all the variables, constraints and everything else you need belong to it as children of the model. Unlike other AMLs I've used, this means you can create multiple unrelated models in one script. Also, the names of each child object are local, so these different models can have the same names for the same things e.g. if you had a cheetah model and a human model that both had a variable called 'torso', one would be 'cheetah.torso' and the other would be 'human.torso' so there'd be no problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sets**\n",
    "\n",
    "Sets are a bit of a tricky concept to describe. Probably the best way to think of them is as indices. They're the dimensions we use to create multiple instances of things (variables, constraints, etc.).\n",
    "\n",
    "Consider the time series nature of the trajectory: for each variable, we have $N$ samples of that variable over the time period. (You might see these time instances referred to as *nodes* or *collocation points* - but more on that later). If we want to simulate the pendulum over 100 nodes (e.g. from 0 to 1 second with a 0.01 second interval), it makes way more sense to define a single variable $\\theta_1$ over the set $n = [1,2,...100]$ than to define 100 individual variables $\\theta_{1_1}, \\theta_{1_2},... \\theta_{1_{100}}$.\n",
    "\n",
    "Objects can be defined over multiple sets. How you choose to do this is really a matter of preference. For instance, one way to define our angle variables for the pendulum would be to use two separate variables, each defined over n: $\\theta_1[n]$ and $\\theta_2[n]$. Alternatively, you could create a link set $l = [1,2]$ and then define a single variable $\\theta[n,l]$. Both accomplish the same thing.\n",
    "\n",
    "From my experience, using more sets results in shorter, more streamlined code and less repetitive coding, but can get a bit hairy and long-winded to navigate and might mean having to write a lot of exceptions to select or exclude specific objects. I'm going to write using simpler set structures for this demo, and it might not be a bad idea to do the same until you're more comforable with pyomo, but I'm not going to tell you how to live your life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 # how many points are in the trajectory\n",
    "m.N = RangeSet(N) # For defining ordered/numerical sets. Works like 'range' in python.\n",
    "m.L = RangeSet(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parameters**\n",
    "Parameters are known values in the model. They can be single instances (e.g. the gravitational constant $g$) or defined over sets (e.g. the mass for each link $m[l]$). In a concrete model, all parameter values must be initialized before it is solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.h = Param(initialize = 0.02) # time step\n",
    "\n",
    "\n",
    "# m here is a local variable: the model given as input to the function, not necessarily our global model 'm'\n",
    "# l is just an iterator: it doesn't have to have the same name as the set \n",
    "m.m = Param(m.L, initialize = 1.0) # mass of links\n",
    "m.len = Param(m.L, initialize = 1.0) # length of links\n",
    "m.dCOM = Param(m.L, initialize = 0.5) # distance from top of link to centre of mass (as a fraction of total length)\n",
    "\n",
    "# IMPORTANT make sure your values are declared as floats: many a long debugging session has eventually led me to find something\n",
    "# unexpectedly has a value of zero because of integer devision gone wrong. Goddamn implicit typing fuuuuuuuuuuuuuuuuuuuuuuuuuuu\n",
    "\n",
    "m.g = Param(initialize = 9.81)\n",
    "m.X0 = Param(initialize = 0.0) # position of fixed base\n",
    "m.Y0 = Param(initialize = 2.0)\n",
    "\n",
    "def calculate_In(m, l): # function for calculating moment of intertia from mass and length\n",
    "    return m.m[l]*m.len[l]**2/12 \n",
    "\n",
    "\n",
    "m.In = Param(m.L, initialize = calculate_In) # moment of inertia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Variables**\n",
    "\n",
    "Variables are what the solver actually solves for. A *solution* is a set of defined values for all variables.\n",
    "\n",
    "We often talk about two types of variables: *decision* and *auxiliary*. Math-wise and code-wise, there isn't any difference  between the two, they just play different roles in the model:\n",
    "\n",
    "Decision variables are the fundamental quantities we need to define our model, and, more than likely, the things we want to know about. Auxiliary variables are written in terms of other variables, and are just there to make the code easier to read or write. For example, if you wanted to perform some operation on the component of a force projected into the $x$ direction, it would be neater to define an auxiliary variable $F_x = $ {some ugly math} and work with that instead of having to faff about with a heap of trig functions every time you need that value.\n",
    "\n",
    "(These sets are fuzzy, obviously... For instance, the acceleration is *auxiliary* in that we define it entirely in terms of other variables, but it's also a useful quantity we might want to output and analyze.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.th = Var(m.N, m.L) # position\n",
    "m.dth = Var(m.N, m.L) # velocity\n",
    "m.ddth = Var(m.N, m.L) # acceleration\n",
    "\n",
    "m.Tc = Var(m.N) # torque at second joint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Constraints**\n",
    "Constraints are \"the rules\". They create relationships between variables and/or parameters, and define which trajectories are acceptable: a *feasible* solution is one which satisfies all the constraints. There may be many feasible solutions, but there's only one *optimal* solution (*OR IS THERE...?*)\n",
    "\n",
    "Constraints can be in the form of equalities or inequalities. Nice ones are linear. Unfortunately for us, most of the ones you need to model robot dynamics are hideously nonlinear. To quote a popular optimization textbook, solving these is often \"more art than technology.\"\n",
    "\n",
    "The constraints we need for our dynamic models can be broken into a few categories:\n",
    "\n",
    "**Variable definitions** Define how the auxiliary variables are calculated from the other variables.\n",
    "\n",
    "**Equations of motion** This is where the Lagrange stuff comes in. These ensure our model obeys physics, by relating the variables according to the dynamic model. If you like, you can think of them as a subcategory of variable definition that calculates the acceleration at each time instant as a function of the position, velocity and forces at that instant.\n",
    "\n",
    "**Integration costraints** These string the variables at individual nodes into a trajectory by relating the values of the position at the current time instant to the position and velocity at the previous one (and the same for the velocities and accelerations) in a way that's consistant with some approximate integration method. For now, I'm going to use the backward Euler method we used to integrate the simulations in the previous tuts, since it's simple and easy to follow, but in a later one I'll introduce orthogonal collocation, the more accurate method we use in our research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic constraints\n",
    "def dynamics(m,n,l): # for theta1\n",
    "    # list the model versions of all quantities in the same order as sym_list\n",
    "    var_list = get_var_list(m,n)\n",
    "    return lamb_EOM[l](*var_list) == 0\n",
    "m.dynamics = Constraint(m.N, m.L, rule = dynamics)\n",
    "\n",
    "# Integration constraints\n",
    "def BwEuler_p(m,n,l): # backward euler integration, for positions\n",
    "    if n > 1:\n",
    "        return m.th[n,l] == m.th[n-1,l] + m.h*m.dth[n,l]\n",
    "    else:\n",
    "        return Constraint.Skip #use this to leave out members of a set that the constraint doesn't apply to\n",
    "m.integrate_p = Constraint(m.N, m.L, rule = BwEuler_p)\n",
    "\n",
    "def BwEuler_v(m,n,l): # backward euler integration, for velocities\n",
    "    if n > 1:\n",
    "        return m.dth[n,l] == m.dth[n-1,l] + m.h*m.ddth[n,l]\n",
    "    else:\n",
    "        return Constraint.Skip \n",
    "m.integrate_v = Constraint(m.N, m.L, rule = BwEuler_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Variable Bounds**\n",
    "\n",
    "\\***NOTE:** These are just special constraints that the solver respects at all iterations.\n",
    "\n",
    "My approach to bounding variables is to do it only where absolutely necessary, but this is another one of those \"more art than technology\" things where it's worth experimenting a bit and figuring out what works best for your specific problem.\n",
    "\n",
    "The main tenets of my philosophy of bounds are \n",
    "1. start with bounds that come from clear physical limitations on the system\n",
    "2. **don't bound auxiliary variables**. If the fundamental variables that make up an aux one are suitably bounded, you shouldn't have to, and doing so will result in a sort of 'double jeopardy' for the solver that will make finding a solution more difficult. \n",
    "\n",
    "Some notes on the above:\n",
    "* Only bound the velocity at the first node. The velocities at other nodes are basically aux because the interpolation constraints relate each one back to the previous one. If your control forces are sensibly bounded and your dynamics work, it shouldn't be able to speed itself up to a crazy speed.\n",
    "* Don't bound the accelerations.\n",
    "* Sometimes, you might create an auxiliary variable specifically to make enacting a physical limitation easier e.g. if you wanted to bound how far out the pendulum extends in the horizontal direction, you'd need to create a variable equal to that value and then put a bound on that. Usually in these cases, the constituent variables won't all have obvious bounds, so you'll likely avoid the double jeopardy thing.\n",
    "* Initial and final conditions are enacted using bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable bounds\n",
    "# In Pyomo, all variables are individual objects, so you have to use a loop to bound them.\n",
    "# (If all the bounds are the same, you can set up a default bound when you create the variable, though)\n",
    "\n",
    "for n in range(1,N+1):\n",
    "#     m.Tc[n].setlb(-50) \n",
    "#     m.Tc[n].setub(50)\n",
    "# bounding actuator forces is tricky. It's usually a good idea, but if your cost function penalizes large forces as is \n",
    "# the case here, you might have an easier time finding a solution without doing so.\n",
    "    \n",
    "    for l in range(1,3):\n",
    "        m.th[n,l].setlb(-np.pi*2) #lower bound\n",
    "        m.th[n,l].setub(np.pi*2) #upper bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cost Function**\n",
    "Ideally, we want our objective to be *convex*, i.e. bowl/cone-shaped with one distinct minimum. Objective variables that can only be positive (e.g. time) or sums of squared things are usually a good way to achieve this.\n",
    "\n",
    "For the pendulum model, let's find the minimum minimum effort solution: so $J = \\sum_{n = 1}^{N} \\tau^2[n]$\n",
    "\n",
    "Why squared? Besides the convexity thing, we want to penalize torque in either direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CostFun(m):\n",
    "    torque_sum = 0\n",
    "    for n in range(1,N+1):\n",
    "            torque_sum += m.Tc[n]**2\n",
    "    return torque_sum\n",
    "m.Cost = Objective(rule = CostFun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Initialization**\n",
    "Opimization problems require an intial guess or *seed* - i.e. a first set of values for all variables - to start off the solving process. \n",
    "\n",
    "If you don't initialize the values before you solve, they will just be set to zero (or one of the bounds if zero isn't within the limits of the variable).\n",
    "\n",
    "Explaining the way we initialize our variables requires a brief digression:\n",
    "\n",
    "### **Local optimization**\n",
    "This is where we answer the question from earlier, *\"OR IS THERE (just one optimal solution)???\"*\n",
    "\n",
    "Answer: yes. There is just one *globally optimal* solution: if you had to lay out every possible solution in the infinite vastness of all possible feasible combinations of values, there would be just one that has the lowest cost out of all of them (or, I suppose some could have an equally low cost, in which case there would be more than one global minimum... but that's besides the point.) That solution is not the one we're going to find. Or maybe it is, if we're really lucky. Thing is, we have no way of knowing, because maths is hard and nobody's figured out how to globally optimize the types of problems we're solving.\n",
    "\n",
    "For large NLP problems, most of the time a *locally optimal* solution is the best you can hope for (and believe me, sometimes just having the thing converge on a solution at all warrants a celebratory trip to the pub.) This is the lowest point *in the region of the solution space* that the solver is able to explore.\n",
    "\n",
    "This is where the initial guess comes in: starting the solver at a different point means it might end up searching a different part of the solution space, and therefore finding a different local minimum.\n",
    "\n",
    "### **Random initialization**\n",
    "For most applications of optimization, the sensible way to initialize your variables would probably be to set them to something that closely resembles what you'd expect feasible values to be, since starting the solver in a \"good\" spot will help it find a solution quicker. (This is definely the best thing to do while you're still in the process of getting your code working.)\n",
    "\n",
    "Unfortunately, our lives aren't that easy... See, because of the thing about the intial guess affecting the region that gets searched, these values are able to bias the solutions you'll get out. Example: if you want to use optimization to investigate what the most efficient gait for a cheetah is, and you initialize the solver with a guess based on a gallop, and you get something resembling a gallop out, that doesn't necessarily mean that galloping is the most efficient thing a cheetah can do. Your solution is just the most efficient one in the space of likely-to-be-gallopish motions in the space near the guess.\n",
    "\n",
    "To avoid this kind of bias, and explore the space widely enough to give ourselves a good chance of finding motions that actually reflect true answers to those types of research questions, we initialize the variables with random values within their ranges, and then run a bunch of these random seeds to generate a large dataset of various locally optimal solutions.\n",
    "\n",
    "Yet again, there are various ways to do this, some more complicated than others. You're trying to find that sweet spot where it's random enough to avoid biasing, but not so much that it struggles to solve. My best simple option would be to just randomize the position variables using small values, and leave everything else to the default null value, or a fixed small value.\n",
    "\n",
    "**Note** random initialization might not be necessary at all for your projects. It depends what you're trying to achieve. Chat to your friendly nabourhood postgrad if you need guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZATION\n",
    "\n",
    "# I'd suggest leaving out random initialization until you know your model converges. \n",
    "# The default null guess usually converges more easily.\n",
    "\n",
    "# for n in range(1,N+1):\n",
    "#     m.Tc[n].value = np.random.uniform(-0.1,0.1)\n",
    "    \n",
    "#     for l in range(1,3):\n",
    "#         m.th[n,l].value = np.random.uniform(-0.1,0.1)\n",
    "#         m.dth[n,l].value = np.random.uniform(-0.1,0.1)\n",
    "#         m.ddth[n,l].value = np.random.uniform(-0.1,0.1)\n",
    "\n",
    "# NOTE: in the above, we are saying m.th[n,l].value = something\n",
    "#       this initialises the value but allows the solver to change it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOUNDARY CONDITIONS\n",
    "\n",
    "# you should to do these after initialization so the values you want to be fixed don't accidentally end up being changed\n",
    "\n",
    "# initial condition\n",
    "for l in range(1,3):\n",
    "    m.th[1,l].fix(0) # if a variable's value is fixed, the solver treats it like a parameter\n",
    "    m.dth[1,l].fix(0) \n",
    "    \n",
    "# final condition\n",
    "m.th[N,1].fix(np.pi)\n",
    "m.th[N,2].fix(np.pi) # remember, absolute orientations\n",
    "\n",
    "for l in range(1,3):\n",
    "    m.dth[N,l].fix(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Solve!**\n",
    "Many different algorithms for solving NLP's exist. I have no idea how any of them work. The one we use is called IPOPT. We use it because \n",
    "1. it's free\n",
    "2. it's fast and works on big problems (though you'll soon learn that this is a relative term...)\n",
    "3. we know the dude behind it (Prof Larry Biegler, Carnegie Mellon)\n",
    "\n",
    "IPOPT can use different linear solvers. The default one that comes with the version of IPOPT you can conda install is called MUMPS, and it's roughly as much fun as the glandular infection that shares its name (it works okay with smallish problems, but has more memory issues than Dory when you're trying anything serious.) \n",
    "\n",
    "The best option is to install a different linear solver: pardiso is alright, the Harwell solvers are better (ma86 being our HG). Just a warning: I haven't ever managed to get an alternative working with the stock ipopt. I had to compile my own, and it was a waking cheese nightmare. MUMPS should be fine for these tutorials, so maybe postpone that kerfuffle until it's absolutely necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# solving\n",
    "opt = SolverFactory('ipopt') # standard issue, garden variety ipopt\n",
    "\n",
    "# If you've managed to install your own version of ipopt, you can call it like:\n",
    "#opt = SolverFactory('ipopt',executable = 'C:/cygwin64/home/Stacey/CoinIpopt/build/bin/ipopt.exe')\n",
    "# opt.options[\"linear_solver\"] = 'ma97'\n",
    "\n",
    "# solver options\n",
    "opt.options[\"print_level\"] = 5 # prints a log with each iteration (you want to this - it's the only way to see progress.)\n",
    "opt.options[\"max_iter\"] = 30000 # maximum number of iterations\n",
    "opt.options[\"max_cpu_time\"] = 300 # maximum cpu time in seconds\n",
    "opt.options[\"Tol\"] = 1e-6 # the tolerance for feasibility. Considers constraints satisfied when they're within this margin.\n",
    "    \n",
    "results = opt.solve(m, tee = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#animate it\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as ani\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "\n",
    "fig1, ax1 = plt.subplots(1,1) #create axes\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "def plot_pendulum(i,m,ax): #update function for animation\n",
    "    ax.clear()\n",
    "    ax.set_xlim([-2,2])\n",
    "    ax.set_ylim([0,4])\n",
    "    \n",
    "    #plot link 1\n",
    "    L1topx = m.X0.value\n",
    "    L1topy = m.Y0.value\n",
    "    L1bottomx = m.X0.value + m.len[1]*np.sin(m.th[i,1].value)\n",
    "    L1bottomy = m.Y0.value - m.len[1]*np.cos(m.th[i,1].value)    \n",
    "    ax.plot([L1topx,L1bottomx],[L1topy,L1bottomy],color='xkcd:blue')\n",
    "    \n",
    "    \n",
    "    #plot link 2\n",
    "    L2bottomx = L1bottomx + m.len[2]*np.sin(m.th[i,2].value)\n",
    "    L2bottomy = L1bottomy - m.len[2]*np.cos(m.th[i,2].value)\n",
    "    ax.plot([L1bottomx,L2bottomx],[L1bottomy,L2bottomy],color='xkcd:red')\n",
    "    \n",
    "update = lambda i: plot_pendulum(i,m,ax1) #lambdify update function\n",
    "\n",
    "animate = ani.FuncAnimation(fig1,update,range(1,N+1),interval = 50,repeat=True) # interval = frame time. 1/50 = 20 fps\n",
    "# animate = ani.FuncAnimation(fig1,update,range(1,N+1),interval = 1000*m.h.value,repeat=True) # if you want it to play at the actual speed\n",
    "\n",
    "HTML(animate.to_html5_video()) #you need to convert the animation to HTML5 to embed it in the notebook\n",
    "# ani.Animation.save(animate,'pendulum_swing.mp4', fps=int(1/h), dpi=300) # if you want to save the animation instead of embedding it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
